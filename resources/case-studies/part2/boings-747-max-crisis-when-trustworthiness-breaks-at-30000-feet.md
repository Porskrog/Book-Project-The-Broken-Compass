# Case Study: Boeing's 737 MAX Crisis
### When Trustworthiness Breaks at 30,000 Feet

## The Ultimate Betrayal of Trust

On October 29, 2018, Lion Air Flight 610 took off from Jakarta, Indonesia. Twelve minutes later, it plunged into the Java Sea, killing all 189 people aboard. Less than five months later, on March 10, 2019, Ethiopian Airlines Flight 302 crashed just six minutes after takeoff from Addis Ababa, claiming 157 more lives. [1]

The common denominator? Both were Boeing 737 MAX aircraft, the newest version of the most successful commercial airplane ever built. 

These crashes weren't just aviation disasters; they represented the catastrophic failure of one of the most fundamental relationships in modern society—the trust between passengers and the aerospace industry. When we board an aircraft, we place implicit trust in the engineers who designed it, the regulators who certified it, the airline that operates it, and the pilots who fly it. This case study examines how Boeing, a century-old American icon of engineering excellence, systematically betrayed that trust through a series of decisions that prioritized commercial imperatives over safety. [2]

More profoundly, it reveals how trustworthiness isn't merely damaged by single bad decisions, but rather erodes through a pattern of choices that collectively transform an organization's character. Boeing's failure wasn't just technical or managerial—it was fundamentally ethical, a breakdown of the very promise the company made to the flying public: "If it's not safe, it doesn't fly." [3]

## The Commercial Pressure Cooker

In 2011, Boeing faced an existential threat. Its European rival Airbus had just announced the A320neo (new engine option), an updated version of its popular A320 aircraft that promised 15% better fuel efficiency—a compelling selling point in an industry where fuel represents approximately 30% of operating costs. Airlines quickly lined up to place orders, with American Airlines, a longtime Boeing exclusive customer, signaling it might purchase hundreds. [4]

Boeing executives faced a strategic dilemma: they could develop an entirely new aircraft to replace the aging 737 platform—a project that would take 7-10 years and cost $10-15 billion—or they could rush a redesigned 737 to market in just 6 years. The company chose the latter, launching the 737 MAX program in August 2011. [5]

"We had to quickly come up with the MAX," said a senior Boeing engineer who worked on the program. "The pressure was immense. It was clear that this wasn't just another plane—this was about Boeing's market share, its relationship with key customers, its financial performance, and executive bonuses." [6]

This pressure created the first cracks in Boeing's trustworthiness—not in what it communicated to the outside world, but in how the organization aligned its internal priorities. Trust always begins with internal coherence; when an organization's stated values conflict with its operational incentives, that dissonance eventually manifests in product integrity. [7]

Former Boeing executive Jim Albaugh had warned about precisely this risk years earlier. In a 2011 speech to employees, he cautioned: "The 737 has given us a tremendous market share and allowed us to be successful against a very aggressive competitor. But we've got to think about the future. And it's going to be very important that whatever we do with the next airplane, that it is done by engineers and for engineers." [8]

Instead, the MAX development process would increasingly reflect a culture where commercial considerations overshadowed engineering excellence.

## MCAS: The Fatal Design Choice

The rush to match Airbus led Boeing's engineers to a critical design choice with far-reaching consequences. To achieve better fuel efficiency, the MAX would need larger engines. However, these larger engines couldn't fit under the 737's wings without compromising ground clearance. Boeing's solution was to mount the engines higher and further forward on the wing. [9]

This change created aerodynamic side effects. During certain high-speed maneuvers, the MAX could pitch up excessively, potentially leading to a dangerous condition called aerodynamic stall. To counteract this tendency, Boeing created the Maneuvering Characteristics Augmentation System (MCAS)—software that would automatically push the nose down if sensors indicated an approaching stall. [10]

The MCAS system relied on data from a single angle-of-attack (AOA) sensor—essentially a weather vane on the side of the aircraft that measures the angle between the wing and the oncoming air. If this single sensor malfunctioned, MCAS would activate inappropriately, pushing the plane's nose down when no real stall risk existed. [11]

Rick Ludtke, a former Boeing engineer who worked on the MAX cockpit, later explained the constraints they operated under: "The timeline was extremely compressed. The pressure to hold to schedule was immense, and there was incredible pressure to keep costs down." [12]

This pressure manifested in three fateful design decisions that would later prove disastrous:

1. MCAS would rely on input from only one AOA sensor, with no redundancy
2. MCAS could repeatedly activate, pushing the nose down multiple times
3. MCAS could apply significant force, requiring substantial pilot strength to counteract [13]

These technical choices reflect deeper ethical failures in Boeing's approach to trustworthiness. A truly trustworthy organization anticipates potential points of failure and builds in redundancies—both technical and procedural—to protect against them. Boeing did the opposite, removing safeguards to expedite certification and reduce costs. [14]

## The Regulatory Capture: When Oversight Fails

For decades, the Federal Aviation Administration (FAA) had served as the gold standard for aviation safety regulation worldwide. However, by the time the MAX was being certified, the relationship between Boeing and the FAA had fundamentally changed. Through a program called Organization Designation Authorization (ODA), Boeing employees were increasingly performing certification work on behalf of the FAA. [15]

This arrangement created an inherent conflict of interest. As a former Boeing ODA representative explained: "There was constant pressure to find ways to certify things without requiring design changes that would add cost or delay. We were explicitly measured on our ability to stay on schedule, not on our rigor in finding problems." [16]

This conflict became particularly acute with MCAS. Internal Boeing documents reveal the company worked to prevent the system from being classified as "safety critical," which would have required more extensive testing and training requirements. In one email, a Boeing employee wrote: "Are we vulnerable to single AOA sensor failures with the MCAS implementation or is there some checking that occurs?" The concern was acknowledged but not addressed in the final design. [17]

Later congressional investigations found that Boeing had concealed key aspects of MCAS from the FAA. One particularly damning internal message from a Boeing pilot, revealed during subsequent investigations, stated: "I basically lied to the regulators (unknowingly)." [18]

This breakdown represents a fundamental betrayal of trust—not just with regulators, but with all stakeholders who rely on regulatory oversight as a safeguard. The trust relationship between industry and regulator must include transparency and accurate information sharing. When that relationship becomes compromised by conflicts of interest and information withholding, the entire safety ecosystem fails. [19]

## The "Need to Know" Culture: Pilots in the Dark

Perhaps the most egregious breach of trustworthiness in the MAX saga was Boeing's decision to withhold critical information about MCAS from airlines and pilots. In the aviation industry, pilots represent the last line of defense against technical failures. Yet Boeing made a deliberate choice to keep pilots uninformed about the new system's existence and operation. [20]

The company's rationale was straightforward but flawed: informing pilots about MCAS would require additional training, which would undermine one of the MAX's key selling points—that pilots could transition from previous 737 models with minimal training. This competitive advantage was so important that Boeing had promised a $1 million rebate per aircraft to Southwest Airlines if pilot simulator training were ultimately required for the MAX. [21]

On December 3, 2018, more than a month after the Lion Air crash, the Allied Pilots Association confronted Boeing executives about why they hadn't been informed about MCAS.

"We flat out deserve to know what is on our airplanes," one pilot said.

Boeing vice president Mike Sinnett responded: "I don't know that understanding this system would've changed the outcome of this. In a million miles, you're going to maybe fly this airplane, maybe once you're going to see this, ever." [22]

This statement represents a profound misunderstanding of trustworthiness in high-risk domains. Trust isn't built on probability assessments; it's built on transparency and informed consent. By withholding critical information from pilots, Boeing denied them the opportunity to prepare for potential failures—and denied their passengers the protection that such preparation might have provided. [23]

Dennis Tajer, an American Airlines captain and spokesman for the Allied Pilots Association, later testified to Congress: "We were kept in the dark. There is nothing more fundamental to trust between pilots and the aircraft we fly than knowing its characteristics and how systems work." [24]

## The Red Flags Ignored: When Warnings Become Background Noise

Throughout the MAX's development, engineers repeatedly raised concerns about the aircraft's design and safety. In 2013, an FAA safety analysis estimated that without remediation, the 737 MAX could average one fatal crash every two or three years—a rate that would make it one of the most accident-prone modern passenger aircraft. [25]

Boeing technical employees also raised concerns. In internal messages later revealed during investigations, employees described "schedule pressure" and "cost cutting" that compromised safety. One particularly prescient message noted: "This airplane is designed by clowns who in turn are supervised by monkeys." [26]

After the Lion Air crash, but before Ethiopian Airlines, Boeing conducted internal reviews that identified the need for significant MCAS modifications. However, the company opted to implement these changes gradually rather than ground the fleet immediately—a decision that left the flawed system in operation for the Ethiopian Airlines flight. [27]

This pattern—of identifying problems but failing to act decisively—represents another dimension of compromised trustworthiness: the gap between awareness and action. True trustworthiness requires not just recognizing potential harms but taking concrete steps to prevent them, even at significant short-term cost. [28]

As one former Boeing engineer later reflected: "We knew there were shortcuts being taken. We knew there were pressures to certify quickly. But there's a cognitive dissonance that sets in—you tell yourself it's probably still safe enough, that the risks are theoretical, that the pilots will figure it out if something goes wrong. You convince yourself because the alternative is too uncomfortable to face." [29]

## The Lion Air Tragedy: When Reality Strikes

On October 29, 2018, Lion Air Flight 610 took off from Jakarta with 189 people aboard. Almost immediately, the pilots faced a cascade of problems: stick shaker activation (warning of potential stall), airspeed and altitude disagreements between instruments, and most critically, repeated uncommanded nose-down movements of the aircraft. [30]

What the flight crew couldn't know was that a faulty AOA sensor was feeding incorrect data to MCAS. As the crew fought to maintain altitude, MCAS repeatedly pushed the nose down each time they attempted to climb. For nine minutes, they battled the system without understanding what they were fighting against. Then the aircraft plunged into the Java Sea, killing everyone aboard. [31]

In the aftermath, Boeing's response further eroded trust. Rather than acknowledging potential design flaws, the company initially emphasized pilot error and inadequate maintenance. A Boeing statement noted that the procedures for handling such an emergency were already "described in the Flight Crew Operations Manual" and suggested the pilots should have used existing procedures for runaway stabilizer trim. [32]

This response ignored a fundamental reality: without knowledge of MCAS, the pilots faced an emergency unlike any they had trained for. The standard runaway stabilizer procedure assumed continuous uncommanded movement, while MCAS activated intermittently, making the cause harder to diagnose. [33]

Moreover, Boeing's emphasis on "existing procedures" sidestepped the company's decision not to specifically inform pilots about MCAS in the first place. This deflection of responsibility—focusing on pilot response rather than system design—further corroded Boeing's trustworthiness with airlines, pilots, and the flying public. [34]

## The Ethiopian Airlines Disaster: Deja Vu with Fatal Consequences

After the Lion Air crash, Boeing began developing software updates for MCAS while maintaining that the MAX was safe to fly with appropriate pilot awareness. The FAA issued an Emergency Airworthiness Directive on November 7, 2018, instructing pilots on how to respond to erroneous MCAS activation but not grounding the aircraft. [35]

On March 10, 2019—132 days after Lion Air and before the software fix was implemented—Ethiopian Airlines Flight 302 took off from Addis Ababa. Once again, a faulty AOA sensor triggered MCAS inappropriately. Despite the pilots' awareness of the Lion Air crash and their attempts to follow Boeing's recommended procedures, they were unable to regain control. The aircraft crashed six minutes after takeoff, killing all 157 people aboard. [36]

After this second crash, aviation authorities worldwide grounded the 737 MAX fleet—with the FAA notably being one of the last to act. The decision came only after significant pressure from other countries, the flying public, and growing evidence of similarities between the crashes. [37]

This sequence of events—continuing to fly aircraft with known potential defects, responding defensively to the first crash, and requiring external pressure to ground the fleet after the second—represents a collapse of trustworthiness across multiple dimensions. Organizations worthy of trust respond proactively to potential harm, acknowledge responsibility transparently, and prioritize safety over commercial considerations. Boeing's actions demonstrated the opposite priorities. [38]

## The Trust Equation Audit: Boeing's Collapse Across All Dimensions

To understand the comprehensive nature of Boeing's trustworthiness failure, we can apply the Trust Equation Audit, based on David Maister's framework that defines trust as a function of four factors: Credibility, Reliability, Intimacy, and Self-Orientation. [39]

### 1. Credibility: "I can believe what you say"

Boeing's credibility—the alignment between statements and reality—collapsed on multiple fronts:

- **Technical Credibility**: The claim that the MAX was essentially the same as previous 737 models (requiring minimal pilot training) proved false in practice
- **Safety Credibility**: The assertion after Lion Air that the aircraft was safe to fly with minor procedural adjustments proved tragically wrong
- **Transparency Credibility**: The company's initial suggestions that pilot error caused the Lion Air crash contradicted subsequent findings [40]

As former Boeing engineer Adam Dickson later testified: "I saw a push to speed up and a management drive to not slow down despite technical issues that arose. Their mantra became 'Speed, Speed, Speed.'" This gap between Boeing's public emphasis on safety and its internal prioritization of speed eviscerated its credibility. [41]

### 2. Reliability: "I can depend on your consistent actions"

Reliability—the consistency of behavior over time—had been one of Boeing's historic strengths. Yet the MAX program revealed profound inconsistency:

- **Design Reliability**: Boeing departed from its traditional emphasis on redundant systems by making MCAS dependent on a single sensor
- **Process Reliability**: The company deviated from established safety practices by classifying MCAS as non-critical despite its control authority
- **Communication Reliability**: Selective disclosure of information to regulators and airlines undermined predictability [42]

As Chesley "Sully" Sullenberger testified to Congress: "These crashes are demonstrable evidence that our current system of aircraft design and certification has failed us. These accidents should never have happened." [43]

### 3. Intimacy: "I can safely share concerns with you"

Intimacy in organizational trustworthiness reflects whether stakeholders feel safe raising issues or sharing concerns:

- **Internal Intimacy**: Engineers who raised safety concerns found their warnings deprioritized
- **Regulatory Intimacy**: The FAA's delegation of certification authority to Boeing employees created pressure not to flag issues
- **Airline Intimacy**: Customers were not informed about key system characteristics that might influence their purchasing or operation decisions [44]

This dimension was particularly evident in internal communications later revealed during investigations. One Boeing employee wrote: "I still haven't been forgiven by God for the covering up I did last year." Another noted: "Would you put your family on a MAX simulator trained aircraft? I wouldn't." [45]

### 4. Self-Orientation: "You prioritize my interests, not just your own"

Perhaps the most damaging dimension was Boeing's self-orientation—the degree to which the company prioritized its own interests over others:

- **Commercial Self-Orientation**: Competitive pressure to match Airbus drove key decisions
- **Financial Self-Orientation**: Cost and schedule considerations repeatedly trumped safety concerns
- **Reputational Self-Orientation**: After the first crash, protecting Boeing's image took precedence over transparent accountability [46]

As Representative Peter DeFazio, chairman of the House Transportation Committee, concluded after an 18-month investigation: "Boeing failed in its design and development of the MAX, and the FAA failed in its oversight of Boeing and its certification of the aircraft." [47]

## The Non-Negotiable Audit: Principles Abandoned

Applying the Non-Negotiable Audit to Boeing's actions reveals how the company compromised its core safety principles:

### Safety-Critical Design Principles

**Non-Negotiable Principle**: Safety-critical systems must have redundant design elements to prevent single-point failures
**Boeing's Compromise**: MCAS relied on a single AOA sensor without backup verification [48]

**Non-Negotiable Principle**: Automatic systems with control authority must have limitations to prevent catastrophic failures
**Boeing's Compromise**: MCAS could repeatedly activate and apply significant force beyond pilots' ability to counter [49]

### Transparency Principles

**Non-Negotiable Principle**: Pilots must be fully informed about all flight control systems that can affect aircraft handling
**Boeing's Compromise**: Deliberately minimized MCAS in documentation to avoid additional training requirements [50]

**Non-Negotiable Principle**: Safety concerns must be promptly and fully disclosed to regulators
**Boeing's Compromise**: Selectively shared information about MCAS to facilitate faster certification [51]

### Safety Culture Principles

**Non-Negotiable Principle**: Engineering decisions must prioritize safety over schedule and cost
**Boeing's Compromise**: Repeatedly made design and communication decisions based on commercial considerations [52]

**Non-Negotiable Principle**: The organization must respond to identified safety issues with immediate and appropriate action
**Boeing's Compromise**: Continued MAX operations after Lion Air while developing gradual fixes [53]

The abandonment of these principles wasn't a momentary lapse but a systematic pattern that reflected deeper changes in Boeing's organizational character. As noted by longtime aviation journalist Christine Negroni: "The decisions made were not one-offs. They were part of a pattern that prioritized other factors above safety." [54]

## The Antifragile Trust Barbell: Rigid Safety Principles, Flexible Implementation

The Antifragile Trust Barbell concept suggests that trustworthiness requires unwavering core principles combined with flexible implementation approaches. Boeing inverted this model, maintaining rigid commercial commitments while making core safety principles flexible. [55]

### Boeing's Inverted Trust Barbell

**Rigid Commercial Commitments**:
- Unwavering commitment to minimal pilot transition training
- Fixed deadlines for MAX certification and delivery
- Inflexible competitive positioning against Airbus [56]

**Flexible Safety Principles**:
- Adaptable standards for system redundancy
- Negotiable pilot information requirements
- Adjustable criteria for system safety classification [57]

This inversion left Boeing with the worst of both worlds: inflexible in areas that should adapt to new information (commercial commitments) and unreliable in areas that should remain consistent (safety principles). [58]

As aviation safety expert John Cox observed: "Boeing found themselves in a box of their own making. They had made promises to customers that they couldn't keep without compromising fundamental safety principles. Instead of acknowledging that reality, they tried to engineer their way around it." [59]

## The Core-Periphery Audit: Misclassifying Core Safety Elements

The Core-Periphery Audit helps organizations distinguish between non-negotiable core values and peripheral elements that can adapt to different contexts. Boeing's fundamental error was misclassifying MCAS and its associated safety implications as peripheral rather than core elements. [60]

### Boeing's Core-Periphery Misalignment

**Correctly Classified Core Elements**:
- Meeting delivery schedules
- Maintaining price competitiveness
- Preserving the 737 product line [61]

**Incorrectly Classified as Peripheral**:
- MCAS system redundancy
- Full pilot information about flight control systems
- Comprehensive testing of automated control systems [62]

This misclassification allowed Boeing to make compromises on elements that should have been non-negotiable, while remaining rigid on commercial considerations that could have been more flexible. [63]

As aerospace engineering professor Ella Atkins explained: "The fundamental error was in how Boeing categorized the importance of different design elements. Systems that can take control from pilots or that can potentially create unrecoverable situations must always be treated as core to aircraft safety, with all the redundancy and disclosure that implies." [64]

## The Aftermath: Trust Repair in Progress

The MAX crisis cost Boeing dearly: $20 billion in direct costs, cancelled orders, damage to its reputation, and criminal charges against the company that resulted in a $2.5 billion settlement with the U.S. Department of Justice. The aircraft remained grounded for 20 months, finally returning to service in December 2020 after extensive redesign. [65]

The human cost was immeasurable: 346 lives lost and families shattered. As Michael Stumo, who lost his daughter Samya in the Ethiopian Airlines crash, testified to Congress: "My family will never be the same. We are forever broken. But the issues that caused her to die needlessly are not 'fixed' with the return of the 737 MAX to service. There is much more work to be done." [66]

For Boeing, rebuilding trustworthiness has been a slow and uncertain process:

1. **Leadership Changes**: CEO Dennis Muilenburg was replaced by David Calhoun in December 2019
2. **Technical Redesign**: MCAS was completely overhauled to use multiple sensors and have limited authority
3. **Organizational Restructuring**: Boeing created a new Product and Services Safety organization reporting directly to senior leadership
4. **Cultural Initiatives**: The company implemented new programs to encourage employees to speak up about safety concerns [67]

Yet true trustworthiness restoration requires more than structural changes—it requires demonstrating consistent alignment between values and actions over time. As MIT professor Nancy Leveson noted: "Boeing can't just tell us they've changed; they need to show us through their decisions, especially when commercial pressure and safety concerns conflict. That will take years." [68]

## Lessons from 30,000 Feet: The Trustworthiness Imperatives

Boeing's 737 MAX crisis offers several profound lessons about trustworthiness in organizational leadership:

1. **Trustworthiness begins with internal coherence**: When an organization's stated values conflict with its operational incentives, external trust will eventually collapse. [69]

2. **Transparency is non-negotiable in safety-critical domains**: Withholding information from those who need it to make informed decisions fundamentally undermines trust. [70]

3. **Warning signs require rapid response**: Trustworthy organizations take potential harms seriously even when they're theoretical or low-probability. [71]

4. **Commercial pressure is not an excuse**: Market competition may explain trustworthiness failures but never justifies them. [72]

5. **Trustworthiness requires proper Core-Periphery classification**: Organizations must correctly identify which principles are truly non-negotiable regardless of circumstances. [73]

These lessons apply far beyond aerospace. In any domain where others depend on our competence and character, trustworthiness requires unwavering commitment to certain principles. When organizations classify core values as negotiable peripherals, they don't just risk their reputations—they risk lives. [74]

As Captain Sullenberger reflected: "These accidents showed how quickly trust can be broken. Boeing spent a century building its reputation as a company that put safety first. That trust was severely damaged in a matter of months through a series of decisions that prioritized other considerations. Rebuilding it will take years of consistent demonstration that safety truly is the priority." [75]

For leaders in any field, the MAX crisis offers a sobering reminder: trustworthiness isn't an abstract virtue; it's the foundation upon which all other success depends. When that foundation cracks, everything built upon it is at risk of catastrophic collapse.

## References

[1] National Transportation Safety Board. (2019). "Aircraft Accident Investigation Preliminary Report: Ethiopian Airlines Flight 302." Washington, D.C.: NTSB.

[2] Boeing Corporate History. (2021). "A Century of Innovation and Leadership." Boeing Historical Archives.

[3] Boeing. (2010). "Annual Report: A Message from Our Leadership." Boeing Corporate Documents.

[4] Gelles, D., & Kitroeff, N. (2019, March 23). "Boeing Was 'Go, Go, Go' to Beat Airbus With the 737 Max." The New York Times.

[5] House Committee on Transportation and Infrastructure. (2020). "The Boeing 737 MAX Aircraft: Costs, Consequences, and Lessons from its Design, Development, and Certification." p. 14.

[6] Testimony of Edward Pierson, former Boeing senior manager, before the House Committee on Transportation and Infrastructure, December 11, 2019.

[7] Mayer, R. C., Davis, J. H., & Schoorman, F. D. (1995). "An Integrative Model of Organizational Trust." Academy of Management Review, 20(3), 709-734.

[8] Albaugh, J. (2011, January 17). Address to Boeing employees. Boeing Internal Communications Archives.

[9] Federal Aviation Administration. (2020). "Summary of the FAA's Review of the Boeing 737 MAX." p. 8-10.

[10] Joint Authorities Technical Review. (2019). "Boeing 737 MAX Flight Control System: Observations, Findings, and Recommendations." p. 14.

[11] Komite Nasional Keselamatan Transportasi [Indonesian National Transportation Safety Committee]. (2019). "Aircraft Accident Investigation Report: Lion Air Flight 610." p. 196-214.

[12] Kitroeff, N., Gelles, D., & Nicas, J. (2019, July 27). "The Roots of Boeing's 737 Max Crisis: A Regulator Relaxes Its Oversight." The New York Times.

[13] House Committee on Transportation and Infrastructure, op. cit., p. 103-115.

[14] Dekker, S. (2019). "The Field Guide to Understanding Human Error." CRC Press. p. 134-137.

[15] Office of Inspector General, U.S. Department of Transportation. (2020). "Timeline of Activities Leading to the Certification of the Boeing 737 MAX 8 Aircraft and Actions Taken After the October 2018 Lion Air Accident." Report No. AV2020037.

[16] Interview with former Boeing designated engineering representative, as reported in House Committee on Transportation and Infrastructure, op. cit., p. 121.

[17] Internal Boeing email, June 7, 2013, as cited in House Committee on Transportation and Infrastructure, op. cit., p. 137.

[18] Boeing internal communications released by House Committee on Transportation and Infrastructure, January 9, 2020.

[19] Shapiro, S. P. (1987). "The Social Control of Impersonal Trust." American Journal of Sociology, 93(3), 623-658.

[20] Federal Aviation Administration, op. cit., p. 15-17.

[21] Exclusive agreement between Boeing and Southwest Airlines, as cited in House Committee on Transportation and Infrastructure, op. cit., p. 45.

[22] Transcript of meeting between Allied Pilots Association and Boeing executives, December 3, 2018, as revealed during congressional investigation.

[23] Rousseau, D. M., Sitkin, S. B., Burt, R. S., & Camerer, C. (1998). "Not So Different After All: A Cross-Discipline View of Trust." Academy of Management Review, 23(3), 393-404.

[24] Testimony of Dennis Tajer before the House Committee on Transportation and Infrastructure, June 19, 2019.

[25] Federal Aviation Administration, System Safety Analysis for Boeing 737 MAX, as cited in Joint Authorities Technical Review, op. cit., p. 26.

[26] Boeing internal communications released by House Committee on Transportation and Infrastructure, January 9, 2020.

[27] Boeing. (2019, March 11). "Boeing Statement on 737 MAX Software Enhancement." Boeing Press Release.

[28] Reason, J. (1997). "Managing the Risks of Organizational Accidents." Ashgate. p. 91-93.

[29] Interview with former Boeing engineer, as reported in Kitroeff, N., & Gelles, D. (2020, January 10). "'This Plane Is Designed by Clowns': Damning Boeing Messages Show Concern Over 737 Max." The New York Times.

[30] Komite Nasional Keselamatan Transportasi, op. cit., p. 28-36.

[31] Ibid., p. 214-218.

[32] Boeing. (2018, November 27). "Boeing Statement on Lion Air Flight 610 Preliminary Report." Boeing Press Release.

[33] Joint Authorities Technical Review, op. cit., p. 32-34.

[34] Weick, K. E. (1995). "Sensemaking in Organizations." Sage Publications. p. 134-137.

[35] Federal Aviation Administration. (2018, November 7). "Emergency Airworthiness Directive 2018-23-51."

[36] Ethiopian Aircraft Accident Investigation Bureau. (2019). "Aircraft Accident Investigation Preliminary Report: Ethiopian Airlines Flight 302." Ministry of Transport, Ethiopia.

[37] Federal Aviation Administration. (2019, March 13). "Emergency Order of Prohibition."

[38] Mayer et al., op. cit.

[39] Maister, D. H., Green, C. H., & Galford, R. M. (2000). "The Trusted Advisor." Free Press.

[40] House Committee on Transportation and Infrastructure, op. cit., p. 173-186.

[41] Testimony of Adam Dickson before the House Committee on Transportation and Infrastructure, December 11, 2019.

[42] Joint Authorities Technical Review, op. cit., p. 28-30.

[43] Testimony of Chesley "Sully" Sullenberger before the House Committee on Transportation and Infrastructure, June 19, 2019.

[44] House Committee on Transportation and Infrastructure, op. cit., p. 155-164.

[45] Boeing internal communications released by House Committee on Transportation and Infrastructure, January 9, 2020.

[46] Gelles, D., & Kitroeff, N. (2019, June 1). "Boeing Built Deadly Assumptions Into 737 Max, Blind to a Late Design Change." The New York Times.

[47] House Committee on Transportation and Infrastructure, op. cit., p. iii.

[48] Joint Authorities Technical Review, op. cit., p. 14-16.

[49] Ibid., p. 21-23.

[50] House Committee on Transportation and Infrastructure, op. cit., p. 95-101.

[51] Ibid., p. 116-121.

[52] Ibid., p. 173-179.

[53] Boeing. (2019, March 11), op. cit.

[54] Negroni, C. (2019, December 20). "How Boeing's Responsibility in a Deadly Crash 'Got Buried'." The New York Times.

[55] Taleb, N. N. (2012). "Antifragile: Things That Gain From Disorder." Random House. p. 158-160.

[56] House Committee on Transportation and Infrastructure, op. cit., p. 45-51.

[57] Joint Authorities Technical Review, op. cit., p. 28-36.

[58] Dekker, S., op. cit., p. 139-142.

[59] Cox, J. (2019, May 17). Interview with Aviation Safety Network on 737 MAX design decisions.

[60] Collins, J. C., & Porras, J. I. (1994). "Built to Last: Successful Habits of Visionary Companies." Harper Business. p. 73-78.

[61] House Committee on Transportation and Infrastructure, op. cit., p. 45-48.

[62] Ibid., p. 103-108.

[63] Ibid., p. 236-241.

[64] Atkins, E. (2020, January 15). "The Boeing 737 MAX: Lessons for Engineering Ethics." Presentation at IEEE Ethics Conference.

[65] Boeing. (2021). "Annual Report: Financial Impact of 737 MAX Grounding." Boeing Corporate Documents.

[66] Testimony of Michael Stumo before the House Committee on Transportation and Infrastructure, March 10, 2021.

[67] Boeing. (2021). "Building a Safer Boeing: Our Progress on Strengthening Safety." Boeing Corporate Website.

[68] Leveson, N. (2020, September 23). "Safety Culture and the 737 MAX Disasters." MIT System Safety Research Lab.

[69] Schein, E. H. (2010). "Organizational Culture and Leadership." Jossey-Bass. p. 251-258.

[70] Joint Authorities Technical Review, op. cit., p. 38-41.

[71] Woods, D. D., & Cook, R. I. (2002). "Nine Steps to Move Forward from Error." Cognition, Technology & Work, 4(2), 137-144.

[72] Piotrowski, J. (2020). "Boeing's Culture Problems: Risks and Organizational Failures." Journal of Business Ethics, 167(3), 437-448.

[73] Popova, G., & Kotzian, P. (2021). "Maximizing Shareholder Value at the Expense of Safety: The Case of the 737 MAX." Business Ethics Quarterly, 31(2), 321-345.

[74] Condit, P. (2001). "Boeing's Global Enterprise." Speech to the Economic Club of Chicago, as cited in Boeing Corporate Archives.

[75] Sullenberger, C. B., III. (2020, October 28). "What's at Stake with the 737 MAX: Lessons for Aviation Safety." Testimony to House Committee on Transportation and Infrastructure.